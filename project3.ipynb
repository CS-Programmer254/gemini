{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "Z = []\n",
    "IMG_SIZE = 150\n",
    "FLOWER_DAISY_DIR = 'path/to/flower/daisy'\n",
    "FLOWER_TULIP_DIR = 'path/to/flower/tulip'\n",
    "FLOWER_SUNFLOWER_DIR = 'path/to/flower/tulip'\n",
    "FLOWER_DANDY_DIR = 'path/to/flower/dandy'\n",
    "FLOWER_ROSE_DIR = 'path/to/flower/rose'\n",
    "def make_train_data(flower_type,DIR):\n",
    "    flower_images = os.listdir(DIR)\n",
    "    for i in range(len(flower_images)):\n",
    "        img = Image.open(os.path.join(DIR,flower_images[i]))\n",
    "        img = img.resize((IMG_SIZE, IMG_SIZE))\n",
    "        data = np.array(img) / 255.0 - 0.5\n",
    "        # data = (np.transpose(data,(1,2,0)))\n",
    "        X.append(data)\n",
    "        Z.append(flower_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Encode Y variable from categorical Z\n",
    "from sklearn import preprocessing\n",
    "labelencoder = preprocessing.LabelEncoder()\n",
    "y = labelencoder.fit_transform(Z)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split x and y into train and test sets in the ratio 75/25\n",
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, y_train, x_test, y_test = train_test_split(X,y)\n",
    "print(\"Train set:\")\n",
    "print(f\"X shape: {x_train.shape}, y shape: {y_train.shape}\")\n",
    "print(\"\\nTest set:\")\n",
    "print(f\"X shape: {x_test.shape}, y shape: {y_test.shape}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Transfer Learning in Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement transfer learning in tensorflow\n",
    "\n",
    "from keras.applications import ResNet50\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "import tensorflow as tf\n",
    "# Load the pre-trained model without the top (classification) layer\n",
    "base_model = ResNet50(weights='imagenet', include_top=False)\n",
    "print(\"Base model loaded\")\n",
    "\n",
    "# Freeze the pre-trained layers so that they are not trainable\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Add custom layers for classification on top of the ResNet50 base\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)  # use a global average pooling layer\n",
    "x = Dense(1024, activation='relu')(x)   # add a fully connected layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create the final model\n",
    "final_model = Model(inputs=base_model.input, outputs=x)\n",
    "\n",
    "# Print summary of the new model\n",
    "final_model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Tensorflow Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "batch_size = 32\n",
    "# Train the model\n",
    "history = model.fit(x_train, y_train, epochs= num_epochs, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Transfer Learning in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement transfer learning in pytorch\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.models import resnet5\n",
    "\n",
    "# Load a pre-trained model (here, ResNet)\n",
    "model = resnet50(pretrained=True)\n",
    "\n",
    "print(\"Model loaded\")\n",
    "\n",
    "# Print the number of input features\n",
    "input_features = model.fc.in_features\n",
    "print(\"Number of input features: \", input_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Remove the last fully connected layer and print the new number of input features \n",
    "model.fc = torch.nn.Identity()\n",
    "output_features = model.fc.in_features\n",
    "print(\"Number of output features: \", output_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Freeze the parameters of the pre-trained layers\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Print the modified resnet50 architecture\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.classifier.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train PyTorch Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "# Create a data loader for training\n",
    "train_dataset = TrainDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "for epoch in range(num_epochs):\n",
    "    for inputs, targets in train_loader:\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update model parameters\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model on the flower dataset\n",
    "# Validation loop\n",
    "with torch.no_grad():\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    for inputs, targets in val_loader:\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # Compute predictions\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        \n",
    "        # Compute accuracy\n",
    "        total_correct += (predicted == targets).sum().item()\n",
    "        total_samples += targets.size(0)\n",
    "\n",
    "    accuracy = total_correct / total_samples\n",
    "    print(f'Validation Accuracy: {accuracy}')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
